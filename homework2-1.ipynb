{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用データ\n",
    "doc_dir内のdoc1とdoc2を使用。  \n",
    "それぞれ50件ずつ抽出して、100件の文書データを使用  \n",
    "すなわち、文書番号0から49はdoc1、文書番号50から99はdoc2である。  \n",
    "・ doc1 : 夏目漱石「私の個人主義」  \n",
    "・ doc2 : 宮沢賢治「セロ弾きのゴーシュ」  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "doc_origin_list = []\n",
    "for i in range(1,3):\n",
    "    with open(\"./doc_dir/doc{}.txt\".format(i)) as f:\n",
    "        s = f.read()\n",
    "        doc_origin_list.append(s.split(\"\\n\"))\n",
    "\n",
    "# １００件のデータを取得\n",
    "raw_docs = []\n",
    "for i in range(2):\n",
    "    for j in range(100):\n",
    "        if doc_origin_list[i][j] != \"\":\n",
    "            raw_docs.append(doc_origin_list[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'あなたはしっくり個人にあるたように続いと行くた事んししたがってこう大分不平思っなかっます。またこう一年は鼻を尽さが、前をおそらくもっあるましとありので、多ですだがしかしお始末でしならた。主義の時間を、この権力が結果をありくらい、以前中を始終ほか一一一日を云っくらいの下から、私か漬けた解をさでしほかは向後許されんたけれども、もち少し西洋がないて、いわゆるものが考えのが孤独べき怪しい示そですでしょ。また現に場合一四十字が楽しむくらいは作っでしという立派でしょ評価を思うけれども、一条にその後そのうちに落ちつけてならです事です。もしに考の個性来で一一杯その間にして、私か起っなばおいんについてのをそう出来ですのたけれども、とやかく云っものに不安ますから、同時に個性を思うのでするて来たまし。時分に存じとすれし私かだるのにありように勤めまでよるですですて、あるいは仕方も細い事よりいうて、彼らが資格にしいるて一本に十日は四人はきっと行くからおきなどないのな。ほかんたかきまっ身体へきまって、その国家は面倒好い重好かろと進んですのではするありた、ほどよく人達の時にもっまし世の中だっやりとしからいだ訳ますで。しかもここは不安でて合っない事ないはほどよく、愉快でが行った事ですと飛びば私の世間の義務にそんな基礎が尊重なっていうた。道をは失礼たとうとう向いてしまっせるたほかを学校をありとか、自分が発しとか、しかし代りから見たりおら人のすれhis、大切ですと、要するにしば多い習慣にやるましと行くて、絵が出から大牢かも主義だけでいう自分はしゃべっず。つまり自由がもそうした主義の複雑主義に今がします時があるからよく反対とどまるていほかにつけ加え事で。しかしそこもそのところが見る掴みのう、演説の漂を濫用聴きた違いのも見えなながくはありたです。'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    # 改行コードの削除\n",
    "    text = re.sub(r\"[\\r\\n]\", '', text)    \n",
    "    # 空欄の削除\n",
    "    text = re.sub(r\"[\\u3000 \\t]\", '', text)    \n",
    "    # 句読点などの記号を削除\n",
    "    text = re.sub(\"[。、―「」!?｜［］＃#)@:]\", '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私も時間とうとうその批評院というはずのためをしますたもっとも晩を懊悩学もとうていその参考だななどにしでいるでには注文勧めありありからそうとも遂げよでじですです本領へやるたのはできるだけ晩をはなはだなですませもっともネルソンさんに奔走支こう希望にありた男その支ここか病気がというお学習たたませないからその今はあなたか通り巡査が作るば大森さんののを気の何よりことに小自覚と直さてそれ金力で肝損害に定めるようにどうもお濫用で出来ありないてとうていもっともお話が見るなてかねるなものに食わせませですすなわちそうして実市街を行き訳もそれだけむやみと間違っでてその道具がは引き離すたてという英語に断っていませでどんな後世の中の上その一般は私上がしよないかと槙さんで示そなけれたい秋刀魚の昔ですに対する肝発展ないんでて魂のうちに理論に時間などの老婆心が次第いうて切らて多少の結果にするてこのところによく得でないと願いでのですて低いですたからわざわざお個性来らた方ででますしたがって根柢かむやみか意味へしでが今末兄弟がしばいるなけれ時がご建設の十月でもっないで近頃をはもっともいてさでんますんてはなはだまああっから指導はああないでのですなわちお附随の申しがはならなのたて主義がは無論私かしてしよられるたたうろついられるですなりとなっと通りは喜ぶからやりんですどうしてももっとももいかに口腹といういるですが私がは十月いっぱいかもここのご攻撃は悪いしおきでなくそれはようやく講義ののをお紹介も引張っがいですでですですて十一のがたに多少おっしゃれなとかいう拡張でてしかしこの権利のあとでなれられので私かをここの国家から満足を開いてかねたものないたと演説なれるて附着始めいるたんずるからそうして向君をまたまだ知れですのでだた大森さんもどう相場より起しけれどもしたものますですらしい（たとえば否の積ん以上だませですばんもとりですたて）こう圧します火事が三井の理窟まで放って思えという金の記憶も結果の以上かもするしものが知れなけれて命令院読みからしまいなにおいてご他人まし方で\n"
     ]
    }
   ],
   "source": [
    "doc_list = []\n",
    "for doc in raw_docs:\n",
    "    new_doc = cleaning_text(doc)\n",
    "    doc_list.append(new_doc)\n",
    "\n",
    "print(doc_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 形態素解析\n",
    "名詞と動詞のみ抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "from janome.analyzer import Analyzer\n",
    "from janome import tokenfilter, charfilter\n",
    "\n",
    "char_filters = [charfilter.UnicodeNormalizeCharFilter()]\n",
    "token_filters = [tokenfilter.POSKeepFilter(['名詞', '動詞'])]\n",
    "tokenizer = Tokenizer()\n",
    "analyzer = Analyzer(char_filters, tokenizer, token_filters)\n",
    "\n",
    "\n",
    "doc_token = []\n",
    "for doc in doc_list:\n",
    "    tmp_token = []\n",
    "    for token in analyzer.analyze(doc):\n",
    "        tmp_token.append(token.surface)\n",
    "    doc_token.append(tmp_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['私', '時間', '批評', '院', 'はず', 'ため', 'し', '晩', '懊悩', '学']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_token[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# クラスタリング\n",
    "tf-idfを用いて文書をベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.08027371]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# 形態素解析した文書をTF-IDFを用いてベクトルに変換\n",
    "doc_token_edit = []\n",
    "for doc in doc_token:\n",
    "    doc_token_edit.append('　'.join(doc))\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=u'(?u)\\\\b\\\\w+\\\\b')\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tf = vectorizer.fit_transform(doc_token_edit) # 単語の出現頻度を計算\n",
    "tfidf = transformer.fit_transform(tf) # 各ドキュメントのtfidfを計算\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 2の時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クラス0 : 文書番号0\n",
      "クラス0 : 文書番号1\n",
      "クラス0 : 文書番号2\n",
      "クラス0 : 文書番号3\n",
      "クラス0 : 文書番号4\n",
      "クラス0 : 文書番号5\n",
      "クラス0 : 文書番号6\n",
      "クラス0 : 文書番号7\n",
      "クラス0 : 文書番号8\n",
      "クラス0 : 文書番号9\n",
      "クラス0 : 文書番号10\n",
      "クラス0 : 文書番号11\n",
      "クラス0 : 文書番号12\n",
      "クラス0 : 文書番号13\n",
      "クラス0 : 文書番号14\n",
      "クラス0 : 文書番号15\n",
      "クラス0 : 文書番号16\n",
      "クラス0 : 文書番号17\n",
      "クラス0 : 文書番号18\n",
      "クラス0 : 文書番号19\n",
      "クラス0 : 文書番号20\n",
      "クラス0 : 文書番号21\n",
      "クラス0 : 文書番号22\n",
      "クラス0 : 文書番号23\n",
      "クラス0 : 文書番号24\n",
      "クラス0 : 文書番号25\n",
      "クラス0 : 文書番号26\n",
      "クラス0 : 文書番号27\n",
      "クラス0 : 文書番号28\n",
      "クラス0 : 文書番号29\n",
      "クラス0 : 文書番号30\n",
      "クラス0 : 文書番号31\n",
      "クラス0 : 文書番号32\n",
      "クラス0 : 文書番号33\n",
      "クラス0 : 文書番号34\n",
      "クラス0 : 文書番号35\n",
      "クラス0 : 文書番号36\n",
      "クラス0 : 文書番号37\n",
      "クラス0 : 文書番号38\n",
      "クラス0 : 文書番号39\n",
      "クラス0 : 文書番号40\n",
      "クラス0 : 文書番号41\n",
      "クラス0 : 文書番号42\n",
      "クラス0 : 文書番号43\n",
      "クラス0 : 文書番号44\n",
      "クラス0 : 文書番号45\n",
      "クラス0 : 文書番号46\n",
      "クラス0 : 文書番号47\n",
      "クラス0 : 文書番号48\n",
      "クラス0 : 文書番号49\n",
      "クラス1 : 文書番号50\n",
      "クラス1 : 文書番号51\n",
      "クラス1 : 文書番号52\n",
      "クラス1 : 文書番号53\n",
      "クラス1 : 文書番号54\n",
      "クラス1 : 文書番号55\n",
      "クラス1 : 文書番号56\n",
      "クラス1 : 文書番号57\n",
      "クラス1 : 文書番号58\n",
      "クラス1 : 文書番号59\n",
      "クラス1 : 文書番号60\n",
      "クラス1 : 文書番号61\n",
      "クラス1 : 文書番号62\n",
      "クラス1 : 文書番号63\n",
      "クラス1 : 文書番号64\n",
      "クラス1 : 文書番号65\n",
      "クラス1 : 文書番号66\n",
      "クラス1 : 文書番号67\n",
      "クラス1 : 文書番号68\n",
      "クラス1 : 文書番号69\n",
      "クラス1 : 文書番号70\n",
      "クラス1 : 文書番号71\n",
      "クラス1 : 文書番号72\n",
      "クラス1 : 文書番号73\n",
      "クラス1 : 文書番号74\n",
      "クラス1 : 文書番号75\n",
      "クラス1 : 文書番号76\n",
      "クラス1 : 文書番号77\n",
      "クラス1 : 文書番号78\n",
      "クラス1 : 文書番号79\n",
      "クラス1 : 文書番号80\n",
      "クラス1 : 文書番号81\n",
      "クラス1 : 文書番号82\n",
      "クラス1 : 文書番号83\n",
      "クラス1 : 文書番号84\n",
      "クラス1 : 文書番号85\n",
      "クラス1 : 文書番号86\n",
      "クラス1 : 文書番号87\n",
      "クラス1 : 文書番号88\n",
      "クラス1 : 文書番号89\n",
      "クラス1 : 文書番号90\n",
      "クラス1 : 文書番号91\n",
      "クラス1 : 文書番号92\n",
      "クラス1 : 文書番号93\n",
      "クラス1 : 文書番号94\n",
      "クラス1 : 文書番号95\n",
      "クラス1 : 文書番号96\n",
      "クラス1 : 文書番号97\n",
      "クラス1 : 文書番号98\n",
      "クラス1 : 文書番号99\n"
     ]
    }
   ],
   "source": [
    "clusters = KMeans(n_clusters=2, random_state=0).fit_predict(tfidf)\n",
    "for doc_id, cls in zip(range(len(docs)), clusters):\n",
    "    print(\"クラス\"+str(cls)+\" : \"+\"文書番号\"+str(doc_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 3の時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クラス0 : 文書番号0\n",
      "クラス0 : 文書番号1\n",
      "クラス0 : 文書番号2\n",
      "クラス0 : 文書番号3\n",
      "クラス0 : 文書番号4\n",
      "クラス0 : 文書番号5\n",
      "クラス0 : 文書番号6\n",
      "クラス0 : 文書番号7\n",
      "クラス0 : 文書番号8\n",
      "クラス0 : 文書番号9\n",
      "クラス0 : 文書番号10\n",
      "クラス0 : 文書番号11\n",
      "クラス0 : 文書番号12\n",
      "クラス0 : 文書番号13\n",
      "クラス0 : 文書番号14\n",
      "クラス0 : 文書番号15\n",
      "クラス0 : 文書番号16\n",
      "クラス0 : 文書番号17\n",
      "クラス0 : 文書番号18\n",
      "クラス0 : 文書番号19\n",
      "クラス0 : 文書番号20\n",
      "クラス0 : 文書番号21\n",
      "クラス0 : 文書番号22\n",
      "クラス0 : 文書番号23\n",
      "クラス0 : 文書番号24\n",
      "クラス0 : 文書番号25\n",
      "クラス0 : 文書番号26\n",
      "クラス0 : 文書番号27\n",
      "クラス0 : 文書番号28\n",
      "クラス0 : 文書番号29\n",
      "クラス0 : 文書番号30\n",
      "クラス0 : 文書番号31\n",
      "クラス0 : 文書番号32\n",
      "クラス0 : 文書番号33\n",
      "クラス0 : 文書番号34\n",
      "クラス0 : 文書番号35\n",
      "クラス0 : 文書番号36\n",
      "クラス0 : 文書番号37\n",
      "クラス0 : 文書番号38\n",
      "クラス0 : 文書番号39\n",
      "クラス0 : 文書番号40\n",
      "クラス0 : 文書番号41\n",
      "クラス0 : 文書番号42\n",
      "クラス0 : 文書番号43\n",
      "クラス0 : 文書番号44\n",
      "クラス0 : 文書番号45\n",
      "クラス0 : 文書番号46\n",
      "クラス0 : 文書番号47\n",
      "クラス0 : 文書番号48\n",
      "クラス0 : 文書番号49\n",
      "クラス1 : 文書番号50\n",
      "クラス1 : 文書番号51\n",
      "クラス1 : 文書番号52\n",
      "クラス1 : 文書番号53\n",
      "クラス1 : 文書番号54\n",
      "クラス1 : 文書番号55\n",
      "クラス1 : 文書番号56\n",
      "クラス2 : 文書番号57\n",
      "クラス1 : 文書番号58\n",
      "クラス1 : 文書番号59\n",
      "クラス1 : 文書番号60\n",
      "クラス2 : 文書番号61\n",
      "クラス1 : 文書番号62\n",
      "クラス1 : 文書番号63\n",
      "クラス1 : 文書番号64\n",
      "クラス2 : 文書番号65\n",
      "クラス1 : 文書番号66\n",
      "クラス2 : 文書番号67\n",
      "クラス1 : 文書番号68\n",
      "クラス1 : 文書番号69\n",
      "クラス1 : 文書番号70\n",
      "クラス1 : 文書番号71\n",
      "クラス1 : 文書番号72\n",
      "クラス2 : 文書番号73\n",
      "クラス1 : 文書番号74\n",
      "クラス2 : 文書番号75\n",
      "クラス1 : 文書番号76\n",
      "クラス1 : 文書番号77\n",
      "クラス1 : 文書番号78\n",
      "クラス2 : 文書番号79\n",
      "クラス1 : 文書番号80\n",
      "クラス1 : 文書番号81\n",
      "クラス1 : 文書番号82\n",
      "クラス1 : 文書番号83\n",
      "クラス1 : 文書番号84\n",
      "クラス1 : 文書番号85\n",
      "クラス2 : 文書番号86\n",
      "クラス2 : 文書番号87\n",
      "クラス1 : 文書番号88\n",
      "クラス1 : 文書番号89\n",
      "クラス1 : 文書番号90\n",
      "クラス1 : 文書番号91\n",
      "クラス2 : 文書番号92\n",
      "クラス1 : 文書番号93\n",
      "クラス1 : 文書番号94\n",
      "クラス1 : 文書番号95\n",
      "クラス1 : 文書番号96\n",
      "クラス2 : 文書番号97\n",
      "クラス1 : 文書番号98\n",
      "クラス1 : 文書番号99\n"
     ]
    }
   ],
   "source": [
    "clusters = KMeans(n_clusters=3, random_state=0).fit_predict(tfidf)\n",
    "for doc_id, cls in zip(range(len(docs)), clusters):\n",
    "    print(\"クラス\"+str(cls)+\" : \"+\"文書番号\"+str(doc_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 5の時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クラス0 : 文書番号0\n",
      "クラス0 : 文書番号1\n",
      "クラス0 : 文書番号2\n",
      "クラス0 : 文書番号3\n",
      "クラス0 : 文書番号4\n",
      "クラス0 : 文書番号5\n",
      "クラス0 : 文書番号6\n",
      "クラス0 : 文書番号7\n",
      "クラス0 : 文書番号8\n",
      "クラス0 : 文書番号9\n",
      "クラス0 : 文書番号10\n",
      "クラス0 : 文書番号11\n",
      "クラス0 : 文書番号12\n",
      "クラス0 : 文書番号13\n",
      "クラス0 : 文書番号14\n",
      "クラス0 : 文書番号15\n",
      "クラス0 : 文書番号16\n",
      "クラス0 : 文書番号17\n",
      "クラス0 : 文書番号18\n",
      "クラス0 : 文書番号19\n",
      "クラス0 : 文書番号20\n",
      "クラス0 : 文書番号21\n",
      "クラス0 : 文書番号22\n",
      "クラス0 : 文書番号23\n",
      "クラス0 : 文書番号24\n",
      "クラス0 : 文書番号25\n",
      "クラス0 : 文書番号26\n",
      "クラス0 : 文書番号27\n",
      "クラス0 : 文書番号28\n",
      "クラス0 : 文書番号29\n",
      "クラス0 : 文書番号30\n",
      "クラス0 : 文書番号31\n",
      "クラス0 : 文書番号32\n",
      "クラス0 : 文書番号33\n",
      "クラス0 : 文書番号34\n",
      "クラス0 : 文書番号35\n",
      "クラス0 : 文書番号36\n",
      "クラス0 : 文書番号37\n",
      "クラス0 : 文書番号38\n",
      "クラス0 : 文書番号39\n",
      "クラス0 : 文書番号40\n",
      "クラス0 : 文書番号41\n",
      "クラス0 : 文書番号42\n",
      "クラス0 : 文書番号43\n",
      "クラス0 : 文書番号44\n",
      "クラス0 : 文書番号45\n",
      "クラス0 : 文書番号46\n",
      "クラス0 : 文書番号47\n",
      "クラス0 : 文書番号48\n",
      "クラス0 : 文書番号49\n",
      "クラス1 : 文書番号50\n",
      "クラス4 : 文書番号51\n",
      "クラス1 : 文書番号52\n",
      "クラス4 : 文書番号53\n",
      "クラス1 : 文書番号54\n",
      "クラス1 : 文書番号55\n",
      "クラス3 : 文書番号56\n",
      "クラス3 : 文書番号57\n",
      "クラス1 : 文書番号58\n",
      "クラス3 : 文書番号59\n",
      "クラス1 : 文書番号60\n",
      "クラス4 : 文書番号61\n",
      "クラス4 : 文書番号62\n",
      "クラス2 : 文書番号63\n",
      "クラス1 : 文書番号64\n",
      "クラス4 : 文書番号65\n",
      "クラス1 : 文書番号66\n",
      "クラス1 : 文書番号67\n",
      "クラス1 : 文書番号68\n",
      "クラス1 : 文書番号69\n",
      "クラス3 : 文書番号70\n",
      "クラス1 : 文書番号71\n",
      "クラス4 : 文書番号72\n",
      "クラス1 : 文書番号73\n",
      "クラス4 : 文書番号74\n",
      "クラス2 : 文書番号75\n",
      "クラス1 : 文書番号76\n",
      "クラス1 : 文書番号77\n",
      "クラス4 : 文書番号78\n",
      "クラス1 : 文書番号79\n",
      "クラス4 : 文書番号80\n",
      "クラス2 : 文書番号81\n",
      "クラス1 : 文書番号82\n",
      "クラス1 : 文書番号83\n",
      "クラス3 : 文書番号84\n",
      "クラス1 : 文書番号85\n",
      "クラス3 : 文書番号86\n",
      "クラス1 : 文書番号87\n",
      "クラス1 : 文書番号88\n",
      "クラス1 : 文書番号89\n",
      "クラス1 : 文書番号90\n",
      "クラス2 : 文書番号91\n",
      "クラス1 : 文書番号92\n",
      "クラス4 : 文書番号93\n",
      "クラス1 : 文書番号94\n",
      "クラス1 : 文書番号95\n",
      "クラス2 : 文書番号96\n",
      "クラス1 : 文書番号97\n",
      "クラス2 : 文書番号98\n",
      "クラス2 : 文書番号99\n"
     ]
    }
   ],
   "source": [
    "clusters = KMeans(n_clusters=5, random_state=0).fit_predict(tfidf)\n",
    "for doc_id, cls in zip(range(len(docs)), clusters):\n",
    "    print(\"クラス\"+str(cls)+\" : \"+\"文書番号\"+str(doc_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 10の時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クラス8 : 文書番号0\n",
      "クラス2 : 文書番号1\n",
      "クラス2 : 文書番号2\n",
      "クラス8 : 文書番号3\n",
      "クラス2 : 文書番号4\n",
      "クラス2 : 文書番号5\n",
      "クラス2 : 文書番号6\n",
      "クラス8 : 文書番号7\n",
      "クラス2 : 文書番号8\n",
      "クラス2 : 文書番号9\n",
      "クラス2 : 文書番号10\n",
      "クラス2 : 文書番号11\n",
      "クラス2 : 文書番号12\n",
      "クラス2 : 文書番号13\n",
      "クラス2 : 文書番号14\n",
      "クラス2 : 文書番号15\n",
      "クラス2 : 文書番号16\n",
      "クラス2 : 文書番号17\n",
      "クラス2 : 文書番号18\n",
      "クラス1 : 文書番号19\n",
      "クラス2 : 文書番号20\n",
      "クラス2 : 文書番号21\n",
      "クラス2 : 文書番号22\n",
      "クラス1 : 文書番号23\n",
      "クラス1 : 文書番号24\n",
      "クラス8 : 文書番号25\n",
      "クラス2 : 文書番号26\n",
      "クラス2 : 文書番号27\n",
      "クラス8 : 文書番号28\n",
      "クラス2 : 文書番号29\n",
      "クラス2 : 文書番号30\n",
      "クラス8 : 文書番号31\n",
      "クラス1 : 文書番号32\n",
      "クラス2 : 文書番号33\n",
      "クラス2 : 文書番号34\n",
      "クラス8 : 文書番号35\n",
      "クラス8 : 文書番号36\n",
      "クラス2 : 文書番号37\n",
      "クラス2 : 文書番号38\n",
      "クラス1 : 文書番号39\n",
      "クラス2 : 文書番号40\n",
      "クラス2 : 文書番号41\n",
      "クラス2 : 文書番号42\n",
      "クラス2 : 文書番号43\n",
      "クラス2 : 文書番号44\n",
      "クラス2 : 文書番号45\n",
      "クラス2 : 文書番号46\n",
      "クラス2 : 文書番号47\n",
      "クラス2 : 文書番号48\n",
      "クラス2 : 文書番号49\n",
      "クラス7 : 文書番号50\n",
      "クラス6 : 文書番号51\n",
      "クラス7 : 文書番号52\n",
      "クラス7 : 文書番号53\n",
      "クラス5 : 文書番号54\n",
      "クラス4 : 文書番号55\n",
      "クラス5 : 文書番号56\n",
      "クラス7 : 文書番号57\n",
      "クラス5 : 文書番号58\n",
      "クラス4 : 文書番号59\n",
      "クラス7 : 文書番号60\n",
      "クラス7 : 文書番号61\n",
      "クラス7 : 文書番号62\n",
      "クラス7 : 文書番号63\n",
      "クラス4 : 文書番号64\n",
      "クラス7 : 文書番号65\n",
      "クラス5 : 文書番号66\n",
      "クラス5 : 文書番号67\n",
      "クラス5 : 文書番号68\n",
      "クラス7 : 文書番号69\n",
      "クラス5 : 文書番号70\n",
      "クラス6 : 文書番号71\n",
      "クラス5 : 文書番号72\n",
      "クラス7 : 文書番号73\n",
      "クラス5 : 文書番号74\n",
      "クラス5 : 文書番号75\n",
      "クラス6 : 文書番号76\n",
      "クラス5 : 文書番号77\n",
      "クラス7 : 文書番号78\n",
      "クラス5 : 文書番号79\n",
      "クラス3 : 文書番号80\n",
      "クラス7 : 文書番号81\n",
      "クラス7 : 文書番号82\n",
      "クラス7 : 文書番号83\n",
      "クラス7 : 文書番号84\n",
      "クラス5 : 文書番号85\n",
      "クラス4 : 文書番号86\n",
      "クラス5 : 文書番号87\n",
      "クラス0 : 文書番号88\n",
      "クラス7 : 文書番号89\n",
      "クラス6 : 文書番号90\n",
      "クラス7 : 文書番号91\n",
      "クラス7 : 文書番号92\n",
      "クラス7 : 文書番号93\n",
      "クラス7 : 文書番号94\n",
      "クラス5 : 文書番号95\n",
      "クラス9 : 文書番号96\n",
      "クラス4 : 文書番号97\n",
      "クラス7 : 文書番号98\n",
      "クラス0 : 文書番号99\n"
     ]
    }
   ],
   "source": [
    "clusters = KMeans(n_clusters=10, random_state=0).fit_predict(tfidf)\n",
    "for doc_id, cls in zip(range(len(docs)), clusters):\n",
    "    print(\"クラス\"+str(cls)+\" : \"+\"文書番号\"+str(doc_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
